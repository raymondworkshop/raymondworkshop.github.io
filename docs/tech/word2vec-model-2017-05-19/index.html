<!doctype html>
<html lang="en">
<meta charset="utf-8">
<!--
<meta http-equiv="content-language” content=”en, zh”>
-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$']]
        },
        svg: {
            fontCache: 'global'
        }
    };
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<title>  - muyun_</title>
<link rel=" stylesheet" href="/static/style.css">
<link rel="stylesheet" href="/static/pygments.css">
<nav>
    <h1><small><a href="/index.html">bestraymond</a></small></h1>
    <ul>
        <li><a href="/index.html"> Blog </a>

            <!--
        <li><a href="/links.html"> Links </a>
            -->
            
        <li><a href="/slides.html"> Slides </a>
            
            <!--
        <li><a href="/projects.html"> Projects </a>
            -->
            
        <li><a href="/bookshelf.html"> Bookshelf </a>
            
           
            <!--
        <li><a href="/talks.html"> Talks </a>
            -->

        <li><a href="/about.html"> About </a>
    </ul>
</nav>

<section class="content">
    <!--
    <header>
        
<title> Word2Vec Model</title>

      </header>
      -->
    
<article class="post">
    <header>
        <h1><strong>Word2Vec Model</strong></h1>
    </header>
    <p class="body"><h4>distributed representations of words</h4>
<p>word2vec is a class of neural network models, trained on unlabelled trainign corpus, that produce a vector for each word in the corpus that encode its valuable syntactic and  semantic informaton .</p>
<h4>Skip-grams (SG) - predict context words given target (position independent)</h4>
<h4>Continuous Bag of Words (CBOW) - Predict target word from bag-of-words context</h4>
<h4>Stochastic Gradient Descent</h4>
<h4>reference</h4>
<ul>
<li>Linguistic Regularities in Continuous Space Word Representations,</li>
<li><a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/">The amazing power of word vectors</a></li>
<li><a href="http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_I_The_Skip-Gram_Model.pdf">Word2vec tutorial</a></li>
<li><a href="http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html">Deep Learning Basics: Neural Networks, Backpropagation and Stochastic Gradient Descent</a></li>
</ul></p>
</article>




</section>


<div class="footer">
    <ul>
        <small>&copy; 2023 <a href="/index.html"></a>bestraymond</small>
    </ul>
</div>