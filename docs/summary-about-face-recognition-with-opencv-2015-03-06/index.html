<!doctype html>
<html lang="en">
<meta charset="utf-8">
<!--
<meta http-equiv="content-language” content=”en, zh”>
-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$']]
        },
        svg: {
            fontCache: 'global'
        }
    };
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<title>  - muyun_</title>
<link rel=" stylesheet" href="/static/style.css">
<link rel="stylesheet" href="/static/pygments.css">
<nav>
    <h1><small><a href="/index.html">_muyun</a></small></h1>
    <ul>
        <li><a href="/index.html"> Writing </a>

            <!--
        <li><a href="/mini-projects.html"> Mini-projects </a>
            -->
        <li><a href="/slides.html"> Slides </a>

            <!--
        <li><a href="/bookshelf.html"> Bookshelf </a>
        -->

            <!--
        <li><a href="/talks.html"> Talks </a>
            -->

        <li><a href="/about.html"> About </a>
    </ul>
</nav>

<section class="content">
    <!--
    <header>
        
<title> Summary about Face Recognition with OpenCV</title>

      </header>
      -->
    
<article class="post">
    <header>
        <h1><strong>Summary about Face Recognition with OpenCV</strong></h1>
    </header>
    <p class="body"><h4>Some ideas and approachments</h4>
<h4>geometric feature</h4>
<ul>
<li>marker points ( position of eyes, ears, noses, ...) are used to build the feature vector (the distance, the angle, ...)</li>
</ul>
<h4>Eigenfaces</h4>
<ul>
<li>
<p>The idea is that a facial image is a point from a high-dim image space, and a high-dim dataset is often described by correlated variables and therefore only a few meaningful dim account for most of the information .</p>
</li>
<li>
<p>alg</p>
<ul>
<li>
<p><a href="http://en.wikipedia.org/wiki/Eigenface/">PCA</a> alg finds the lower-dim subspace with maximum variance (with the mean) in data.  ( that is, to turn a set of possibly correlated variables into a smaller set of uncorrelated variables) .</p>
</li>
<li>
<p>There is a TRICK here in computing the eigenvectors: a M x N matrix (M rows, N columns) with M &gt; N can only have N - 1 non-zero eigenvalues, so we can take the eigenvalue decomposition S of size N x N instead .</p>
</li>
<li>
<p>The approach maximizes the total scatter, but if the variance is generated by an external source like light, components with a maximum variance over all classes aren't nessarily useful for classification.</p>
</li>
</ul>
</li>
<li>
<p>The [API] [http://docs.opencv.org/trunk/modules/contrib/doc/facerec/facerec_api.html] in OpenCV:</p>
<ul>
<li>
<p>Ptr<FaceRecognizer> createEigenFaceRecognizer(int num_components, double threshold)
        (~\sources\modules\contrib\src\facerec.cpp)</p>
<ul>
<li>Perform the PCA</li>
<li>(~\modules\core\src\matmul.cpp)
  pca(data, Mat(), CV_PCA_DATA_AS_ROW, _num_components)</li>
</ul>
<p>The parameter <em>num_components</em> means that how many principal components to retain (it is not  larger than the number of training samples) .</p>
<ul>
<li>Get the feature vectors (y here is the principal component )
  Mat y = subspaceProject(_eigenvectors, _mean, data.row(sampleIdx)</li>
</ul>
<p>The parameter <em>threshold</em> here gives a upper distance limit in the prediction (It is the parameter <em>minDist</em> in the  Eigenfaces::predict())</p>
<p>Eigenfaces::predict(InputArray _src, int &amp;minClass, double &amp;minDist)</p>
<p>Each test sample is projected into PCA subspace,and get the related label based on the NORM_L2 distance in the trained subspace.</p>
</li>
</ul>
</li>
</ul>
<h4>Fisherfaces</h4>
<h4>Local Binary Patterns Histograms (LBPH)</h4>
<ul>
<li>
<p>idea</p>
<ul>
<li>
<p>The focus is only on extracting local features of an object, thus the features in this waywill have a low-dim implicitly.</p>
</li>
<li>
<p>Also, the local description has to be a bit robust against image illumination variations (things like scale,translation or rotation), so the Local Binary Patterns (LBP) is given to summarize the local structure in a image by comparing each pixel with its neighborhood .</p>
</li>
</ul>
</li>
<li>
<p>The [API] [http://docs.opencv.org/trunk/modules/contrib/doc/facerec/facerec_api.html] in OpenCV Ptr<FaceRecognizer> createLBPHFaceRecognizer(int radius,int neighbors, int grid_x, int grid_y, double threshold) Calculate lbp image</p>
<ul>
<li>elbp(src[sampleIdx],_radius,_neighbors)</li>
</ul>
<p>The parameters <em>radius</em> and <em>neighbors</em> are used in the local binary pattern creation</p>
<ul>
<li>Get spatial histogram from this lbp image</li>
</ul>
</li>
</ul>
<pre class="lang-c++"><span class="w">      </span><span class="n">Mat</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spatial_histogram</span><span class="p">(</span><span class="w"></span>
<span class="w">                </span><span class="n">lbp_image</span><span class="p">,</span><span class="w"> </span><span class="cm">/* lbp_image */</span><span class="w"></span>
<span class="w">                </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">pow</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">_neighbors</span><span class="p">))),</span><span class="w"> </span><span class="cm">/* number of possible patterns */</span><span class="w"></span>
<span class="w">                </span><span class="n">_grid_x</span><span class="p">,</span><span class="w"> </span><span class="cm">/* grid size x */</span><span class="w"></span>
<span class="w">                </span><span class="n">_grid_y</span><span class="p">,</span><span class="w"> </span><span class="cm">/* grid size y */</span><span class="w"></span>
<span class="w">                </span><span class="nb">true</span><span class="p">)</span><span class="w"></span>
</pre>
<pre><code>  The parameters *gird_x* and *grid_y* control the grid size of the spatial histograms.
          At last the feature vectors (p here is the spatial histogram) are given .

  LBPH::predict(InputArray _src, int &amp;minClass, double &amp;minDist)

  compareHist(_histograms[sampleIdx], query, CV_COMP_CHISQR)

  Chi-square test is used for the distance measure
</code></pre>
<h4>The Performance</h4>
<ul>
<li>
<p>Receiver operating characteristic (<a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC</a>)</p>
<ul>
<li>A ROC space is defined by TAR (I.e., the rate of genuine attempts accepted) and FAR(I.e., the rate of impostor attempts accepted) as y and x axes respectively, which depicts relative trade-offs between true positive (benefits) and false positive (costs).</li>
</ul>
</li>
<li>
<p>Cumulative Match Characteristic (CMC)</p>
<ul>
<li>It plots the probability of identification against the returned 1:N candidate list size. It shows the probability that a given user appears in different sized candidate lists.</li>
</ul>
</li>
</ul>
<h4>Reference</h4>
<ul>
<li><a href="http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html">Face Recognition with OpenCV</a></li>
<li><a href="http://en.wikipedia.org/wiki/Eigenface/">Eigenface</a></li>
<li><a href="http://docs.opencv.org/trunk/modules/contrib/doc/facerec/facerec_api.html">FaceRecognizer API</a></li>
<li><a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC</a></li>
</ul></p>
</article>




</section>


<div class="footer">
    <ul>
        <small>&copy; 2022 <a href="/index.html"></a>_muyun</small>
    </ul>
</div>